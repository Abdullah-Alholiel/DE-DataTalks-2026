id: 01_ingest_data
namespace: zoomcamp.module4

description: |
  Downloads Green, Yellow (2019-2020) and FHV (2019) taxi data,
  converts to Parquet, and loads into DuckDB.

tasks:
  - id: ingest_all_data
    type: io.kestra.plugin.scripts.python.Script
    taskRunner:
      type: io.kestra.plugin.scripts.runner.docker.Docker
      image: python:3.11-slim
      memory:
        memory: 4GB
    beforeCommands:
      - pip install duckdb requests
    script: |
      import duckdb
      import requests
      from pathlib import Path

      BASE_URL = "https://github.com/DataTalksClub/nyc-tlc-data/releases/download"

      def download_file(url, filepath):
          print(f"  Downloading {url} ...")
          response = requests.get(url, stream=True)
          response.raise_for_status()
          with open(filepath, 'wb') as f:
              for chunk in response.iter_content(chunk_size=8192):
                  f.write(chunk)

      def download_and_convert(taxi_type, years):
          data_dir = Path("data") / taxi_type
          data_dir.mkdir(exist_ok=True, parents=True)
          for year in years:
              for month in range(1, 13):
                  parquet_filename = f"{taxi_type}_tripdata_{year}-{month:02d}.parquet"
                  parquet_filepath = data_dir / parquet_filename
                  if parquet_filepath.exists():
                      print(f"Skipping {parquet_filename} (already exists)")
                      continue
                  csv_gz_filename = f"{taxi_type}_tripdata_{year}-{month:02d}.csv.gz"
                  csv_gz_filepath = data_dir / csv_gz_filename
                  try:
                      download_file(f"{BASE_URL}/{taxi_type}/{csv_gz_filename}", csv_gz_filepath)
                  except Exception as e:
                      print(f"  ERROR downloading {csv_gz_filename}: {e}")
                      continue
                  print(f"  Converting {csv_gz_filename} to Parquet...")
                  con = duckdb.connect()
                  con.execute(f"""
                      COPY (SELECT * FROM read_csv_auto('{csv_gz_filepath}'))
                      TO '{parquet_filepath}' (FORMAT PARQUET)
                  """)
                  con.close()
                  csv_gz_filepath.unlink()
                  print(f"  Completed {parquet_filename}")

      # Download all data
      for taxi_type in ["yellow", "green"]:
          print(f"\n--- {taxi_type.upper()} ---")
          download_and_convert(taxi_type, years=[2019, 2020])

      print("\n--- FHV ---")
      download_and_convert("fhv", years=[2019])

      # Load into DuckDB
      con = duckdb.connect("taxi_rides_ny.duckdb")
      con.execute("CREATE SCHEMA IF NOT EXISTS prod")

      for taxi_type in ["yellow", "green"]:
          print(f"Loading {taxi_type} data into DuckDB...")
          con.execute(f"""
              CREATE OR REPLACE TABLE prod.{taxi_type}_tripdata AS
              SELECT * FROM read_parquet('data/{taxi_type}/*.parquet', union_by_name=true)
          """)
          count = con.execute(f"SELECT COUNT(*) FROM prod.{taxi_type}_tripdata").fetchone()[0]
          print(f"  {taxi_type}_tripdata: {count:,} rows loaded")

      print("Loading fhv data into DuckDB...")
      con.execute("""
          CREATE OR REPLACE TABLE prod.fhv_tripdata AS
          SELECT * FROM read_parquet('data/fhv/*.parquet', union_by_name=true)
      """)
      count = con.execute("SELECT COUNT(*) FROM prod.fhv_tripdata").fetchone()[0]
      print(f"  fhv_tripdata: {count:,} rows loaded")

      con.close()
      print("\nAll data ingested successfully!")